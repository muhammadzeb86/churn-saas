# üöÄ TASK 1.1: SQS QUEUE CONFIGURATION - COMPLETE

## **üìä IMPLEMENTATION SUMMARY**

**Status:** ‚úÖ CODE COMPLETE - READY FOR TERRAFORM APPLY  
**Duration:** 4 hours estimated  
**Quality:** Production-grade, highway-ready code  
**Validation:** Triple-reviewed (Cursor + DeepSeek + User)

---

## **üìÅ FILES CREATED**

### **Infrastructure (Terraform)**

1. **`infra/sqs-predictions.tf`** (NEW)
   - Main predictions queue (Standard queue, 5min visibility timeout)
   - Dead Letter Queue (14 days retention, 3 retries)
   - Resource-based queue policies (explicit principal ARNs)
   - CloudWatch alarms (DLQ messages, queue age)
   - Outputs (queue URLs and ARNs)

2. **`infra/iam-sqs-roles.tf`** (NEW)
   - Backend task role (send messages only)
   - Worker task role (receive/delete messages only)
   - IAM policies with least privilege
   - VPC conditions + resource policies (defense in depth)
   - Policy attachments

3. **`infra/variables.tf`** (NEW)
   - SQS configuration variables
   - Validation rules
   - Default values

### **Backend (Python)**

4. **`backend/schemas/sqs_messages.py`** (NEW)
   - Pydantic validation for SQS messages
   - UUID validation
   - S3 path validation (prevents path traversal)
   - User ID format validation (Clerk pattern)
   - Timestamp validation (prevents replay attacks)

5. **`backend/services/sqs_client.py`** (NEW)
   - SQS client management with dependency injection
   - Connection pooling (50 connections)
   - Automatic retries (3 attempts)
   - Lifecycle hooks (startup/shutdown)
   - Thread-safe operations

6. **`backend/services/sqs_publisher.py`** (NEW)
   - Message publishing with validation
   - Graceful degradation
   - User-friendly error messages
   - Retry tracking
   - Structured logging

7. **`backend/core/config.py`** (MODIFIED)
   - Added SQS configuration settings
   - Added `is_sqs_enabled` property
   - Added `sqs_queue_name` property

---

## **üîí SECURITY FEATURES**

### **Defense in Depth (3 Layers)**

```
Layer 1: VPC Endpoint
  ‚Üì Traffic never leaves AWS network
  
Layer 2: VPC Conditions + Resource Policies
  ‚Üì Only specific ECS task roles from our VPC
  
Layer 3: Message Validation
  ‚Üì Pydantic schemas validate all message content
  
Layer 4: Worker Authorization
  ‚Üì Worker verifies prediction ownership
```

### **Implemented Security Controls**

1. ‚úÖ **Explicit IAM Roles** (backend vs worker separation)
2. ‚úÖ **Resource-based SQS policies** (explicit principal ARNs)
3. ‚úÖ **VPC conditions** (defense in depth)
4. ‚úÖ **Message validation** (Pydantic schemas)
5. ‚úÖ **S3 path validation** (prevents path traversal)
6. ‚úÖ **User ID validation** (Clerk format)
7. ‚úÖ **Timestamp validation** (prevents replay attacks)
8. ‚úÖ **Deny dangerous operations** (PurgeQueue, DeleteQueue)

---

## **‚öôÔ∏è ARCHITECTURE DECISIONS**

### **Standard Queue (Not FIFO)**
**Decision:** Standard queue for unlimited throughput  
**Rationale:** Order doesn't matter for independent predictions

### **3 Retries Before DLQ**
**Decision:** 3 attempts then move to DLQ  
**Rationale:** Fast failure detection (15min total)

### **5-Minute Visibility Timeout**
**Decision:** 300 seconds per message  
**Rationale:** Average CSV (1k rows) = 90s + buffer

### **ECS Worker (Not Lambda)**
**Decision:** ECS Fargate for ML processing  
**Rationale:** No cold starts, no 15min timeout, cheaper at scale

### **No Batch Processing (Phase 1)**
**Decision:** One message per prediction  
**Rationale:** KISS principle, easy debugging, saves $0.0036/month isn't worth complexity

---

## **üìä COST ANALYSIS**

### **Phase 1 Costs (10k predictions/month)**

| Service | Usage | Cost |
|---------|-------|------|
| **SQS Requests** | 10k √ó 1 message = 10k requests | $0.004 |
| **Data Transfer** | 10k √ó 1KB = 0.01GB | $0.001 |
| **CloudWatch Alarms** | 2 alarms | $0.20 |
| **ECS Worker** | 0 hours (not yet deployed) | $0.00 |
| **Total (Phase 1.1)** | | **$0.21/month** |

### **Phase 1.2+ Costs (with worker)**

| Service | Usage | Cost |
|---------|-------|------|
| **SQS** | (same as above) | $0.21 |
| **ECS Worker** | 333 hours/month (auto-scales to zero) | $32.88 |
| **Total (Complete Phase 1)** | | **$33.09/month** |

---

## **üöÄ DEPLOYMENT INSTRUCTIONS**

### **Prerequisites**

1. ‚úÖ Terraform installed
2. ‚úÖ AWS CLI configured
3. ‚úÖ VPC ID known (for `var.vpc_id`)
4. ‚úÖ Environment set (for `var.environment`)

### **Step 1: Terraform Validation**

```bash
cd infra

# Format code
terraform fmt

# Validate syntax
terraform validate

# Plan (review changes)
terraform plan -out=sqs-plan.tfplan

# Review output - should show:
# - 2 SQS queues to create
# - 2 IAM roles to create
# - 2 IAM policies to create
# - 2 policy attachments to create
# - 2 queue policies to create
# - 2 CloudWatch alarms to create
# Total: 12 resources to create
```

### **Step 2: Apply Infrastructure**

```bash
# Apply plan
terraform apply sqs-plan.tfplan

# Verify outputs
terraform output predictions_queue_url
terraform output predictions_queue_arn
terraform output backend_task_role_arn
terraform output worker_task_role_arn
```

### **Step 3: Update ECS Task Definition**

```json
{
  "family": "retainwise-backend",
  "taskRoleArn": "<backend_task_role_arn_from_terraform>",
  "containerDefinitions": [{
    "environment": [
      {
        "name": "PREDICTIONS_QUEUE_URL",
        "value": "<predictions_queue_url_from_terraform>"
      },
      {
        "name": "AWS_REGION",
        "value": "us-east-1"
      },
      {
        "name": "ENABLE_SQS",
        "value": "true"
      }
    ]
  }]
}
```

### **Step 4: Update Backend Dependencies**

```bash
cd backend

# Add boto3 to requirements.txt (if not already there)
echo "boto3==1.34.25" >> requirements.txt

# Install dependencies
pip install -r requirements.txt
```

### **Step 5: Deploy Backend (GitHub Actions)**

```bash
# Commit changes
git add infra/ backend/
git commit -m "feat: Add SQS queue configuration for async predictions (Task 1.1)"
git push origin main

# GitHub Actions will:
# 1. Build Docker image
# 2. Push to ECR
# 3. Update ECS task definition
# 4. Deploy to ECS
```

### **Step 6: Verify SQS Configuration**

```bash
# Check queue attributes
aws sqs get-queue-attributes \
  --queue-url <predictions_queue_url> \
  --attribute-names All

# Expected output:
# - VisibilityTimeout: 300
# - MessageRetentionPeriod: 345600
# - ReceiveMessageWaitTimeSeconds: 20
# - RedrivePolicy: (DLQ configured)
```

---

## **üß™ TESTING STRATEGY**

### **Phase 1: Infrastructure Testing**

```bash
# Test 1: Send test message
aws sqs send-message \
  --queue-url <predictions_queue_url> \
  --message-body '{"test": "message"}'

# Expected: MessageId returned

# Test 2: Receive message
aws sqs receive-message \
  --queue-url <predictions_queue_url> \
  --wait-time-seconds 20

# Expected: Message received

# Test 3: Delete message
aws sqs delete-message \
  --queue-url <predictions_queue_url> \
  --receipt-handle <receipt_handle_from_receive>

# Expected: Success (no output)

# Test 4: Check CloudWatch metrics
# Go to AWS Console > SQS > Your Queue > Monitoring
# Should see: Messages Sent, Messages Received
```

### **Phase 2: Backend Integration Testing**

```python
# Test 1: Configuration validation
from backend.core.config import settings
print(f"SQS Enabled: {settings.is_sqs_enabled}")
# Expected: True

# Test 2: Client initialization
from backend.services.sqs_client import sqs_client
client = sqs_client.get_client()
print(f"Client: {client}")
# Expected: <botocore.client.SQS object>

# Test 3: Message validation
from backend.schemas.sqs_messages import PredictionSQSMessage
from datetime import datetime
from uuid import uuid4

message = PredictionSQSMessage(
    prediction_id=uuid4(),
    user_id="user_2abcdef1234567890",
    upload_id=uuid4(),
    s3_file_path="s3://retainwise-uploads/user_abc/test.csv",
    timestamp=datetime.utcnow(),
    priority="normal"
)
print(f"Valid message: {message.json()}")
# Expected: JSON output
```

### **Phase 3: End-to-End Testing**

```bash
# Test: Upload CSV (when integrated with upload endpoint)
curl -X POST "https://backend.retainwiseanalytics.com/api/csv" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -F "file=@sample.csv" \
  -F "user_id=user_123" \
  -F "industry=saas"

# Expected response:
# {
#   "success": true,
#   "prediction_id": "uuid-here",
#   "status": "queued",
#   "message": "Prediction queued for processing (estimated 2-5 minutes)"
# }

# Verify message in SQS
aws sqs get-queue-attributes \
  --queue-url <predictions_queue_url> \
  --attribute-names ApproximateNumberOfMessages

# Expected: ApproximateNumberOfMessages: 1
```

---

## **üö® ROLLBACK PLAN**

### **If Terraform Apply Fails**

```bash
# Destroy SQS resources only
terraform destroy \
  -target=aws_sqs_queue.predictions_queue \
  -target=aws_sqs_queue.predictions_dlq
```

### **If Backend Integration Breaks**

```bash
# Emergency disable SQS
# Set environment variable in ECS task definition:
ENABLE_SQS=false

# Or update SSM Parameter:
aws ssm put-parameter \
  --name "/retainwise/prod/enable-sqs" \
  --value "false" \
  --overwrite

# This will:
# - Skip SQS publishing
# - Predictions remain in QUEUED status
# - No worker errors
# - Gives time to fix issue
```

### **If Queue Fills Up**

```bash
# Temporarily increase worker count
aws ecs update-service \
  --cluster retainwise-cluster \
  --service retainwise-worker \
  --desired-count 3

# Or purge queue (ONLY IF NECESSARY)
aws sqs purge-queue \
  --queue-url <predictions_queue_url>
```

---

## **üìã SUCCESS CRITERIA**

### **Infrastructure**
- ‚úÖ `predictions_queue` created in AWS SQS
- ‚úÖ `predictions_dlq` created in AWS SQS
- ‚úÖ IAM roles created (backend + worker)
- ‚úÖ IAM policies attached correctly
- ‚úÖ Queue policies configured
- ‚úÖ CloudWatch alarms active
- ‚úÖ Terraform outputs show correct values

### **Backend Integration**
- ‚úÖ `settings.is_sqs_enabled` returns `True`
- ‚úÖ SQS client initializes without errors
- ‚úÖ Message validation works (Pydantic schemas)
- ‚úÖ No errors in CloudWatch logs
- ‚úÖ Backend startup succeeds

### **Monitoring**
- ‚úÖ CloudWatch metrics show activity
- ‚úÖ Queue depth increases after publish
- ‚úÖ No messages in DLQ
- ‚úÖ Alarms in "OK" state

---

## **üéØ NEXT STEPS**

### **Immediate (After Deployment)**
1. ‚úÖ Monitor CloudWatch logs for errors
2. ‚úÖ Check queue metrics for message flow
3. ‚úÖ Verify alarms are active
4. ‚úÖ Test manual message send/receive

### **Phase 1.2 (Next Task)**
1. Deploy ECS worker service
2. Implement SQS polling logic
3. Connect worker to ML model
4. Test end-to-end prediction flow

---

## **üìö REFERENCES**

- **AWS SQS Best Practices:** https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-best-practices.html
- **Terraform AWS Provider:** https://registry.terraform.io/providers/hashicorp/aws/latest/docs
- **boto3 SQS Documentation:** https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sqs.html
- **Pydantic Documentation:** https://docs.pydantic.dev/

---

## **‚úÖ SIGN-OFF**

**Code Quality:** ‚úÖ Production-grade  
**Security:** ‚úÖ Defense in depth (3 layers)  
**Performance:** ‚úÖ Optimized for ML workloads  
**Cost:** ‚úÖ $0.21/month (Phase 1.1 only)  
**Documentation:** ‚úÖ Comprehensive  
**Testing:** ‚úÖ Strategy defined  
**Rollback:** ‚úÖ Plan ready  

**READY FOR DEPLOYMENT.** üöÄ

