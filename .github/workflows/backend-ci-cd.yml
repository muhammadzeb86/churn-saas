name: Backend CI/CD Pipeline

on:
  push:
    branches: [ main ]
    paths:
      - 'backend/**'
      - 'infra/**'
      - '.github/workflows/backend-ci-cd.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'backend/**'
      - 'infra/**'

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: retainwise-backend
  ECS_CLUSTER: retainwise-cluster
  ECS_SERVICE: retainwise-service
  ECS_TASK_DEFINITION: retainwise-backend

jobs:
  # Job 1: Build and Test Backend
  build-and-test:
    name: Build and Test Backend
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        submodules: recursive
        lfs: true
        
    - name: Show commit and tree
      run: |
        echo "=== COMMIT INFO ==="
        git rev-parse HEAD
        git log --oneline -5
        echo "=== WORKSPACE STRUCTURE ==="
        ls -la
        echo "=== BACKEND STRUCTURE ==="
        ls -la backend/
        echo "=== MODELS STRUCTURE ==="
        ls -la backend/models/ || true
        echo "=== MODELS __INIT__.PY CONTENT ==="
        cat backend/models/__init__.py || true
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install Python dependencies
      run: |
        # Run tests from project root
        pip install -r backend/requirements-test.txt
        
    - name: Verify import works in CI
      env:
        PYTHONPATH: ${{ github.workspace }}
      run: |
        echo "=== PYTHONPATH ==="
        echo $PYTHONPATH
        echo "=== PYTHON MODULE TEST ==="
        python - << 'PY'
        import sys
        print("sys.path:", sys.path)
        try:
            import backend.models
            print("SUCCESS: backend.models imported")
            print("Available models:", backend.models.__all__)
        except Exception as e:
            print("ERROR importing backend.models:", e)
            import traceback
            traceback.print_exc()
        PY
        
    - name: Run backend tests (if any)
      env:
        ENVIRONMENT: test
        DATABASE_URL: sqlite+aiosqlite:///./test.db
        AWS_REGION: us-east-1
        S3_BUCKET: test-bucket
        PREDICTIONS_QUEUE_URL: ""
        PYTHONPATH: ${{ github.workspace }}
      run: |
        # Run tests from project root
        python -m pytest backend/tests/ -v --tb=short
        
    - name: Build Docker image
      run: |
        # Build from repo root using backend/Dockerfile
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REPOSITORY:${{ github.sha }} \
          .
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REPOSITORY:latest \
          .
  deploy:
    name: Deploy to AWS
    runs-on: ubuntu-latest
    needs: build-and-test
    if: github.ref == 'refs/heads/main'
    
    permissions:
      id-token: write  # Required for OIDC
      contents: read
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials with OIDC
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::908226940571:role/retainwise-cicd-ecs-deployment-role
        aws-region: ${{ env.AWS_REGION }}
        
    - name: Set deployment environment variables
      run: |
        echo "GIT_COMMIT_SHA=${{ github.sha }}" >> $GITHUB_ENV
        echo "BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_ENV
        echo "DEPLOYMENT_ID=deploy-${{ github.run_number }}" >> $GITHUB_ENV
        echo "APP_VERSION=2.0.0" >> $GITHUB_ENV
        
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
      
    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Build from repo root using backend/Dockerfile
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
          .
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
          .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
        
    - name: Check for infrastructure changes
      id: check-infra
      run: |
        # Check if any files in infra/ directory were modified
        if git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep -q "^infra/"; then
          echo "infra_changed=true" >> $GITHUB_OUTPUT
        else
          echo "infra_changed=false" >> $GITHUB_OUTPUT
        fi
        
    - name: Setup Terraform
      if: steps.check-infra.outputs.infra_changed == 'true'
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: "1.5.0"
        
    - name: Terraform Init
      if: steps.check-infra.outputs.infra_changed == 'true'
      run: |
        cd infra
        terraform init
        
    - name: Terraform Plan
      if: steps.check-infra.outputs.infra_changed == 'true'
      run: |
        cd infra
        terraform plan -out=tfplan
        
    - name: Terraform Apply
      if: steps.check-infra.outputs.infra_changed == 'true'
      run: |
        cd infra
        terraform apply -auto-approve tfplan
        
    - name: Download task definition
      run: |
        aws ecs describe-task-definition --task-definition $ECS_TASK_DEFINITION \
        --query taskDefinition > task-definition.json
        
    - name: Update task definition with version tracking
      run: |
        # Add version tracking environment variables to task definition
        jq '.containerDefinitions[0].environment += [
          {"name": "GIT_COMMIT_SHA", "value": "'${{ github.sha }}'"},
          {"name": "BUILD_TIME", "value": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"},
          {"name": "DEPLOYMENT_ID", "value": "deploy-${{ github.run_number }}"},
          {"name": "APP_VERSION", "value": "2.0.0"},
          {"name": "ENVIRONMENT", "value": "production"}
        ]' task-definition.json > task-definition-updated.json
        mv task-definition-updated.json task-definition.json
        
    - name: Fill in the new image ID in the Amazon ECS task definition
      id: task-def
      uses: aws-actions/amazon-ecs-render-task-definition@v1
      with:
        task-definition: task-definition.json
        container-name: retainwise-backend
        image: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }}
        
    - name: Deploy Amazon ECS task definition
      uses: aws-actions/amazon-ecs-deploy-task-definition@v1
      with:
        task-definition: ${{ steps.task-def.outputs.task-definition }}
        service: ${{ env.ECS_SERVICE }}
        cluster: ${{ env.ECS_CLUSTER }}
        wait-for-service-stability: true
        
    - name: Update Golden Task Definition AFTER deployment
      run: |
        # Get the ACTUAL task definition that the service is now using
        # The deploy action registers a new task definition internally, so we need to get it from the service
        DEPLOYED_TD=$(aws ecs describe-services \
          --cluster $ECS_CLUSTER \
          --services $ECS_SERVICE \
          --query 'services[0].taskDefinition' \
          --output text)
        
        echo "Service is now running: $DEPLOYED_TD"
        
        # Validate the ARN format
        if [[ ! "$DEPLOYED_TD" =~ ^arn:aws:ecs:[a-z0-9-]+:[0-9]+:task-definition/[a-zA-Z0-9_-]+:[0-9]+$ ]]; then
          echo "❌ Error: Invalid task definition ARN format: $DEPLOYED_TD"
          exit 1
        fi
        
        echo "Updating Golden Task Definition to: $DEPLOYED_TD"
        
        # Update the SSM parameter with retry logic
        MAX_RETRIES=3
        RETRY_COUNT=0
        
        while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
          if aws ssm put-parameter \
            --name "/retainwise/golden-task-definition" \
            --value "$DEPLOYED_TD" \
            --overwrite \
            --description "Golden task definition ARN - authoritative source of truth for production deployments"; then
            
            # Verify the update
            STORED_ARN=$(aws ssm get-parameter --name "/retainwise/golden-task-definition" --query 'Parameter.Value' --output text)
            if [ "$STORED_ARN" == "$DEPLOYED_TD" ]; then
              echo "✅ Golden Task Definition updated and verified successfully!"
              echo "✅ Golden parameter now matches deployed service: $DEPLOYED_TD"
              break
            else
              echo "❌ Warning: Parameter update verification failed. Retrying..."
            fi
          else
            echo "❌ Warning: Failed to update parameter. Retrying..."
          fi
          
          RETRY_COUNT=$((RETRY_COUNT + 1))
          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "❌ Error: Failed to update Golden Task Definition after $MAX_RETRIES attempts"
            exit 1
          fi
          sleep 5
        done
        
    - name: Verify deployment and golden task definition
      run: |
        echo "=== Verifying Service Status ==="
        SERVICE_INFO=$(aws ecs describe-services \
          --cluster $ECS_CLUSTER \
          --services $ECS_SERVICE \
          --query 'services[0].{Status:status,RunningCount:runningCount,DesiredCount:desiredCount,TaskDefinition:taskDefinition}' \
          --output json)
        
        echo "$SERVICE_INFO" | jq '.'
        
        # Extract current task definition
        CURRENT_TD=$(echo "$SERVICE_INFO" | jq -r '.TaskDefinition')
        
        echo "=== Verifying Golden Task Definition ==="
        GOLDEN_TD=$(aws ssm get-parameter --name "/retainwise/golden-task-definition" --query 'Parameter.Value' --output text)
        
        echo "Current Task Definition: $CURRENT_TD"
        echo "Golden Task Definition:  $GOLDEN_TD"
        
        if [ "$CURRENT_TD" != "$GOLDEN_TD" ]; then
          echo "❌ ERROR: Task definition mismatch!"
          echo "Service is running $CURRENT_TD but golden parameter is $GOLDEN_TD"
          exit 1
        fi
        
        echo "✅ Deployment completed and verified successfully!"
        echo "✅ Service and golden task definition are in sync!"
          
    - name: Check for database migration changes
      id: check-migrations
      run: |
        # Check if any migration files were modified
        if git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep -q "^backend/alembic/"; then
          echo "migrations_changed=true" >> $GITHUB_OUTPUT
        else
          echo "migrations_changed=false" >> $GITHUB_OUTPUT
        fi
        
    - name: Run database migrations
      if: steps.check-migrations.outputs.migrations_changed == 'true'
      run: |
        # Get subnet and security group IDs from the service
        SUBNET_IDS=$(aws ecs describe-services --cluster $ECS_CLUSTER --services $ECS_SERVICE --query 'services[0].networkConfiguration.awsvpcConfiguration.subnets[]' --output text | tr '\t' ',')
        SECURITY_GROUP_IDS=$(aws ecs describe-services --cluster $ECS_CLUSTER --services $ECS_SERVICE --query 'services[0].networkConfiguration.awsvpcConfiguration.securityGroups[]' --output text | tr '\t' ',')
        
        echo "Running database migrations..."
        
        # Create a one-off migration task
        MIGRATION_TASK_ARN=$(aws ecs run-task \
          --cluster $ECS_CLUSTER \
          --task-definition $ECS_TASK_DEFINITION \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],securityGroups=[$SECURITY_GROUP_IDS],assignPublicIp=ENABLED}" \
          --overrides '{"containerOverrides":[{"name":"retainwise-backend","command":["python","backend/scripts/run_migrations.py"]}]}' \
          --region $AWS_REGION \
          --query 'tasks[0].taskArn' \
          --output text)
        
        echo "Migration task started: $MIGRATION_TASK_ARN"
        
        # Wait for migration task to complete
        echo "Waiting for migration task to complete..."
        while true; do
          TASK_STATUS=$(aws ecs describe-tasks \
            --cluster $ECS_CLUSTER \
            --tasks $MIGRATION_TASK_ARN \
            --query 'tasks[0].lastStatus' \
            --output text \
            --region $AWS_REGION)
          
          echo "Migration task status: $TASK_STATUS"
          
          if [ "$TASK_STATUS" = "STOPPED" ]; then
            # Check if task succeeded
            TASK_EXIT_CODE=$(aws ecs describe-tasks \
              --cluster $ECS_CLUSTER \
              --tasks $MIGRATION_TASK_ARN \
              --query 'tasks[0].containers[0].exitCode' \
              --output text \
              --region $AWS_REGION)
            
            if [ "$TASK_EXIT_CODE" = "0" ]; then
              echo "Migration completed successfully!"
              break
            else
              echo "Migration failed with exit code: $TASK_EXIT_CODE"
              exit 1
            fi
          elif [ "$TASK_STATUS" = "RUNNING" ]; then
            echo "Migration still running, waiting..."
            sleep 10
          else
            echo "Unexpected task status: $TASK_STATUS"
            exit 1
          fi
        done
        
    - name: Verify migration success
      if: steps.check-migrations.outputs.migrations_changed == 'true'
      run: |
        echo "Migration verification completed successfully!"
        echo "Database schema is now up to date."
        
    - name: Get load balancer URL
      run: |
        # Get the load balancer DNS name from Terraform outputs or AWS CLI
        if [ -f "infra/terraform.tfstate" ]; then
          echo "Load Balancer URL: $(cd infra && terraform output -raw load_balancer_dns)"
        else
          echo "Load Balancer URL: Check AWS Console for ALB DNS name"
        fi

  # Job 3: Health Check (optional)
  health-check:
    name: Health Check
    runs-on: ubuntu-latest
    needs: deploy
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Wait for application to be ready
      run: |
        # Wait a bit for the application to fully start
        sleep 60
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
        
    - name: Get load balancer URL and test endpoints
      run: |
        # Use the production domain name instead of raw ALB DNS to avoid SSL certificate errors
        DOMAIN="api.retainwiseanalytics.com"
        
        echo "Testing health endpoint at: https://$DOMAIN/health"
        curl -f https://$DOMAIN/health || echo "Health check failed"
        
        echo "Testing version endpoint at: https://$DOMAIN/__version"
        VERSION_RESPONSE=$(curl -s https://$DOMAIN/__version)
        echo "Version response: $VERSION_RESPONSE"
        
        # Verify version endpoint contains expected fields
        if echo "$VERSION_RESPONSE" | jq -e '.commit_sha, .build_time, .deployment_id' > /dev/null; then
          echo "✅ Version endpoint working correctly!"
          echo "✅ Deployment verified successfully!"
        else
          echo "❌ Version endpoint missing expected fields"
          exit 1
        fi 
