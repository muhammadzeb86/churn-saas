name: Backend CI/CD Pipeline

on:
  push:
    branches: [ main ]
    paths:
      - 'backend/**'
      - 'infra/**'
      - '.github/workflows/backend-ci-cd.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'backend/**'
      - 'infra/**'

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: retainwise-backend
  ECS_CLUSTER: retainwise-cluster
  ECS_SERVICE: retainwise-service
  ECS_TASK_DEFINITION: retainwise-backend

jobs:
  # Job 1: Build and Test Backend
  build-and-test:
    name: Build and Test Backend
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        submodules: recursive
        lfs: true
        
    - name: Show commit and tree
      run: |
        echo "=== COMMIT INFO ==="
        git rev-parse HEAD
        git log --oneline -5
        echo "=== WORKSPACE STRUCTURE ==="
        ls -la
        echo "=== BACKEND STRUCTURE ==="
        ls -la backend/
        echo "=== MODELS STRUCTURE ==="
        ls -la backend/models/ || true
        echo "=== MODELS __INIT__.PY CONTENT ==="
        cat backend/models/__init__.py || true
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install Python dependencies
      run: |
        # Run tests from project root
        pip install -r backend/requirements-test.txt
        
    - name: Verify import works in CI
      env:
        PYTHONPATH: ${{ github.workspace }}
      run: |
        echo "=== PYTHONPATH ==="
        echo $PYTHONPATH
        echo "=== PYTHON MODULE TEST ==="
        python - << 'PY'
        import sys
        print("sys.path:", sys.path)
        try:
            import backend.models
            print("SUCCESS: backend.models imported")
            print("Available models:", backend.models.__all__)
        except Exception as e:
            print("ERROR importing backend.models:", e)
            import traceback
            traceback.print_exc()
        PY
        
    - name: Run backend tests (if any)
      env:
        ENVIRONMENT: test
        DATABASE_URL: sqlite+aiosqlite:///./test.db
        AWS_REGION: us-east-1
        S3_BUCKET: test-bucket
        PREDICTIONS_QUEUE_URL: ""
        PYTHONPATH: ${{ github.workspace }}
      run: |
        # Run tests from project root
        python -m pytest backend/tests/ -v --tb=short
        
    - name: Build Docker image
      run: |
        # Build from repo root using backend/Dockerfile
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REPOSITORY:${{ github.sha }} \
          .
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REPOSITORY:latest \
          .
  deploy:
    name: Deploy to AWS
    runs-on: ubuntu-latest
    needs: build-and-test
    if: github.ref == 'refs/heads/main'
    
    permissions:
      id-token: write  # Required for OIDC
      contents: read
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials with OIDC
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::908226940571:role/retainwise-cicd-ecs-deployment-role
        aws-region: ${{ env.AWS_REGION }}
        
    - name: Set deployment environment variables
      run: |
        echo "GIT_COMMIT_SHA=${{ github.sha }}" >> $GITHUB_ENV
        echo "BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_ENV
        echo "DEPLOYMENT_ID=deploy-${{ github.run_number }}" >> $GITHUB_ENV
        echo "APP_VERSION=2.0.0" >> $GITHUB_ENV
        
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
      
    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Build from repo root using backend/Dockerfile
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
          .
        docker build -f backend/Dockerfile \
          --build-arg GIT_SHA=${{ github.sha }} \
          --build-arg BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
          -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
          .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
    
    # ========================================
    # TERRAFORM INFRASTRUCTURE MANAGEMENT
    # ========================================
    # Phase 3.5: Terraform state management enabled
    # State stored in S3 with DynamoDB locking
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0
    
    - name: Terraform Init
      working-directory: ./infra
      run: |
        echo "üîß Initializing Terraform with S3 backend..."
        terraform init -reconfigure
        echo "‚úÖ Terraform initialized successfully"
    
    - name: Terraform Format Check
      working-directory: ./infra
      continue-on-error: true
      run: |
        echo "üîç Checking Terraform formatting..."
        terraform fmt -check -recursive || echo "‚ö†Ô∏è Some files need formatting (non-blocking)"
    
    - name: Terraform Validate
      working-directory: ./infra
      run: |
        echo "üîç Validating Terraform configuration..."
        terraform validate
        echo "‚úÖ Terraform configuration is valid"
    
    - name: Check for infrastructure changes
      id: infra-changes
      run: |
        # Check if infra directory has changes in this commit
        INFRA_CHANGED=$(git diff --name-only HEAD~1 HEAD | grep '^infra/' || echo "")
        if [ -n "$INFRA_CHANGED" ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "‚úÖ Infrastructure changes detected"
          echo "$INFRA_CHANGED"
        else
          echo "changes=false" >> $GITHUB_OUTPUT
          echo "‚ÑπÔ∏è No infrastructure changes detected"
        fi
    
    - name: Terraform Plan
      if: steps.infra-changes.outputs.changes == 'true'
      working-directory: ./infra
      run: |
        echo "üìã Planning Terraform changes..."
        terraform plan -out=tfplan -input=false
        terraform show -no-color tfplan > plan.txt
        echo "‚úÖ Terraform plan completed"
    
    - name: Show Terraform Plan
      if: steps.infra-changes.outputs.changes == 'true'
      working-directory: ./infra
      run: |
        echo "=== TERRAFORM PLAN ==="
        cat plan.txt
        echo "======================"
    
    - name: Terraform Apply
      if: steps.infra-changes.outputs.changes == 'true'
      working-directory: ./infra
      run: |
        echo "üöÄ Applying Terraform changes..."
        terraform apply -auto-approve tfplan
        echo "‚úÖ Terraform apply completed successfully"
    
    - name: Verify Terraform State
      working-directory: ./infra
      run: |
        echo "üîç Verifying Terraform state..."
        terraform state list || echo "No resources in state yet (expected for first run)"
        echo "‚úÖ Terraform state verification complete"
        
    # ========================================
    # ECS DEPLOYMENT (Manual - Will migrate to Terraform)
    # ========================================
        
    - name: Get SQS queue URL from AWS
      id: get-queue-url
      run: |
        echo "Fetching SQS queue URL from AWS..."
        QUEUE_URL=$(aws sqs get-queue-url --queue-name prod-retainwise-predictions-queue --query 'QueueUrl' --output text 2>/dev/null || echo "")
        if [ -z "$QUEUE_URL" ]; then
          echo "‚ö†Ô∏è  Queue URL not found, using default"
          QUEUE_URL="https://sqs.us-east-1.amazonaws.com/908226940571/prod-retainwise-predictions-queue"
        fi
        echo "predictions_queue_url=$QUEUE_URL" >> $GITHUB_OUTPUT
        echo "‚úÖ Queue URL: $QUEUE_URL"
        
    - name: Download task definition
      run: |
        aws ecs describe-task-definition --task-definition $ECS_TASK_DEFINITION \
          --query taskDefinition > task-definition.json
        
    - name: Update task definition with version tracking and SQS
      run: |
        # Add version tracking + SQS environment variables to task definition
        # Build the jq command dynamically based on whether queue URL was found
        if [ -n "${{ steps.get-queue-url.outputs.predictions_queue_url }}" ]; then
          jq '.containerDefinitions[0].environment += [
            {"name": "GIT_COMMIT_SHA", "value": "'${{ github.sha }}'"},
            {"name": "BUILD_TIME", "value": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"},
            {"name": "DEPLOYMENT_ID", "value": "deploy-${{ github.run_number }}"},
            {"name": "APP_VERSION", "value": "2.0.0"},
            {"name": "ENVIRONMENT", "value": "production"},
            {"name": "PREDICTIONS_QUEUE_URL", "value": "'${{ steps.get-queue-url.outputs.predictions_queue_url }}'"},
            {"name": "ENABLE_SQS", "value": "true"}
          ]' task-definition.json > task-definition-updated.json
          echo "‚úÖ Added SQS environment variables"
        else
          jq '.containerDefinitions[0].environment += [
            {"name": "GIT_COMMIT_SHA", "value": "'${{ github.sha }}'"},
            {"name": "BUILD_TIME", "value": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"},
            {"name": "DEPLOYMENT_ID", "value": "deploy-${{ github.run_number }}"},
            {"name": "APP_VERSION", "value": "2.0.0"},
            {"name": "ENVIRONMENT", "value": "production"}
          ]' task-definition.json > task-definition-updated.json
          echo "‚ö†Ô∏è  Queue URL not found - SQS environment variables NOT added"
        fi
        mv task-definition-updated.json task-definition.json
        
    - name: Fill in the new image ID in the Amazon ECS task definition
      id: task-def
      uses: aws-actions/amazon-ecs-render-task-definition@v1
      with:
        task-definition: task-definition.json
        container-name: retainwise-backend
        image: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }}
        
    - name: Deploy Amazon ECS task definition
      uses: aws-actions/amazon-ecs-deploy-task-definition@v1
      with:
        task-definition: ${{ steps.task-def.outputs.task-definition }}
        service: ${{ env.ECS_SERVICE }}
        cluster: ${{ env.ECS_CLUSTER }}
        wait-for-service-stability: true
        
    - name: Update Golden Task Definition AFTER deployment
      run: |
        # Get the ACTUAL task definition that the service is now using
        # The deploy action registers a new task definition internally, so we need to get it from the service
        DEPLOYED_TD=$(aws ecs describe-services \
          --cluster $ECS_CLUSTER \
          --services $ECS_SERVICE \
          --query 'services[0].taskDefinition' \
          --output text)
        
        echo "Service is now running: $DEPLOYED_TD"
        
        # Validate the ARN format
        if [[ ! "$DEPLOYED_TD" =~ ^arn:aws:ecs:[a-z0-9-]+:[0-9]+:task-definition/[a-zA-Z0-9_-]+:[0-9]+$ ]]; then
          echo "‚ùå Error: Invalid task definition ARN format: $DEPLOYED_TD"
          exit 1
        fi
        
        echo "Updating Golden Task Definition to: $DEPLOYED_TD"
        
        # Update the SSM parameter with retry logic
        MAX_RETRIES=3
        RETRY_COUNT=0
        
        while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
          if aws ssm put-parameter \
            --name "/retainwise/golden-task-definition" \
            --value "$DEPLOYED_TD" \
            --overwrite \
            --description "Golden task definition ARN - authoritative source of truth for production deployments"; then
            
            # Verify the update
            STORED_ARN=$(aws ssm get-parameter --name "/retainwise/golden-task-definition" --query 'Parameter.Value' --output text)
            if [ "$STORED_ARN" == "$DEPLOYED_TD" ]; then
              echo "‚úÖ Golden Task Definition updated and verified successfully!"
              echo "‚úÖ Golden parameter now matches deployed service: $DEPLOYED_TD"
              break
            else
              echo "‚ùå Warning: Parameter update verification failed. Retrying..."
            fi
          else
            echo "‚ùå Warning: Failed to update parameter. Retrying..."
          fi
          
          RETRY_COUNT=$((RETRY_COUNT + 1))
          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "‚ùå Error: Failed to update Golden Task Definition after $MAX_RETRIES attempts"
            exit 1
          fi
          sleep 5
        done
        
    - name: Verify deployment and golden task definition
      run: |
        echo "=== Verifying Service Status ==="
        SERVICE_INFO=$(aws ecs describe-services \
          --cluster $ECS_CLUSTER \
          --services $ECS_SERVICE \
          --query 'services[0].{Status:status,RunningCount:runningCount,DesiredCount:desiredCount,TaskDefinition:taskDefinition}' \
          --output json)
        
        echo "$SERVICE_INFO" | jq '.'
        
        # Extract current task definition
        CURRENT_TD=$(echo "$SERVICE_INFO" | jq -r '.TaskDefinition')
        
        echo "=== Verifying Golden Task Definition ==="
        GOLDEN_TD=$(aws ssm get-parameter --name "/retainwise/golden-task-definition" --query 'Parameter.Value' --output text)
        
        echo "Current Task Definition: $CURRENT_TD"
        echo "Golden Task Definition:  $GOLDEN_TD"
        
        if [ "$CURRENT_TD" != "$GOLDEN_TD" ]; then
          echo "‚ùå ERROR: Task definition mismatch!"
          echo "Service is running $CURRENT_TD but golden parameter is $GOLDEN_TD"
          exit 1
        fi
        
        echo "‚úÖ Deployment completed and verified successfully!"
        echo "‚úÖ Service and golden task definition are in sync!"
          
    # PRODUCTION-GRADE: Always run migrations (Alembic is idempotent)
    - name: Run database migrations
      run: |
        # Get subnet and security group IDs from the service
        SUBNET_IDS=$(aws ecs describe-services --cluster $ECS_CLUSTER --services $ECS_SERVICE --query 'services[0].networkConfiguration.awsvpcConfiguration.subnets[]' --output text | tr '\t' ',')
        SECURITY_GROUP_IDS=$(aws ecs describe-services --cluster $ECS_CLUSTER --services $ECS_SERVICE --query 'services[0].networkConfiguration.awsvpcConfiguration.securityGroups[]' --output text | tr '\t' ',')
        
        echo "Running database migrations..."
        
        # Create a one-off migration task
        MIGRATION_TASK_ARN=$(aws ecs run-task \
          --cluster $ECS_CLUSTER \
          --task-definition $ECS_TASK_DEFINITION \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],securityGroups=[$SECURITY_GROUP_IDS],assignPublicIp=ENABLED}" \
          --overrides '{"containerOverrides":[{"name":"retainwise-backend","command":["python","backend/scripts/run_migrations.py"]}]}' \
          --region $AWS_REGION \
          --query 'tasks[0].taskArn' \
          --output text)
        
        echo "Migration task started: $MIGRATION_TASK_ARN"
        
        # Wait for migration task to complete (with timeout)
        echo "Waiting for migration task to complete..."
        MAX_WAIT=600  # 10 minutes timeout
        ELAPSED=0
        
        while [ $ELAPSED -lt $MAX_WAIT ]; do
          TASK_STATUS=$(aws ecs describe-tasks \
            --cluster $ECS_CLUSTER \
            --tasks $MIGRATION_TASK_ARN \
            --query 'tasks[0].lastStatus' \
            --output text \
            --region $AWS_REGION)
          
          echo "Migration task status: $TASK_STATUS (elapsed: ${ELAPSED}s)"
          
          if [ "$TASK_STATUS" = "STOPPED" ]; then
            # Check if task succeeded
            TASK_EXIT_CODE=$(aws ecs describe-tasks \
              --cluster $ECS_CLUSTER \
              --tasks $MIGRATION_TASK_ARN \
              --query 'tasks[0].containers[0].exitCode' \
              --output text \
              --region $AWS_REGION)
            
            if [ "$TASK_EXIT_CODE" = "0" ]; then
              echo "‚úÖ Migration completed successfully!"
              break
            else
              echo "‚ùå Migration failed with exit code: $TASK_EXIT_CODE"
              
              # Get detailed failure reason
              STOP_REASON=$(aws ecs describe-tasks \
                --cluster $ECS_CLUSTER \
                --tasks $MIGRATION_TASK_ARN \
                --query 'tasks[0].stoppedReason' \
                --output text \
                --region $AWS_REGION)
              
              echo "Stop reason: $STOP_REASON"
              
              # Get container logs if available
              echo "Fetching container logs..."
              LOG_STREAM=$(aws ecs describe-tasks \
                --cluster $ECS_CLUSTER \
                --tasks $MIGRATION_TASK_ARN \
                --query 'tasks[0].containers[0].name' \
                --output text \
                --region $AWS_REGION)
              
              exit 1
            fi
          elif [ "$TASK_STATUS" = "RUNNING" ]; then
            echo "Migration task is running..."
            sleep 15
            ELAPSED=$((ELAPSED + 15))
          elif [ "$TASK_STATUS" = "PROVISIONING" ] || [ "$TASK_STATUS" = "PENDING" ]; then
            echo "Migration task is provisioning/pending..."
            sleep 10
            ELAPSED=$((ELAPSED + 10))
          elif [ "$TASK_STATUS" = "DEPROVISIONING" ]; then
            echo "Migration task is deprovisioning (completing)..."
            sleep 5
            ELAPSED=$((ELAPSED + 5))
          else
            echo "‚ö†Ô∏è  Unexpected task status: $TASK_STATUS"
            echo "Continuing to wait..."
            sleep 10
            ELAPSED=$((ELAPSED + 10))
          fi
        done
        
        # Check if we hit timeout
        if [ $ELAPSED -ge $MAX_WAIT ]; then
          echo "‚ùå Migration task timed out after ${MAX_WAIT} seconds"
          exit 1
        fi
        
    - name: Verify migration success
      if: steps.check-migrations.outputs.migrations_changed == 'true'
      run: |
        echo "Migration verification completed successfully!"
        echo "Database schema is now up to date."
        
    - name: Get load balancer URL
      run: |
        # Get the load balancer DNS name from Terraform outputs or AWS CLI
        if [ -f "infra/terraform.tfstate" ]; then
          echo "Load Balancer URL: $(cd infra && terraform output -raw load_balancer_dns)"
        else
          echo "Load Balancer URL: Check AWS Console for ALB DNS name"
        fi

  # Job 3: Health Check (optional)
  health-check:
    name: Health Check
    runs-on: ubuntu-latest
    needs: deploy
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Wait for application to be ready
      run: |
        # Wait a bit for the application to fully start
        sleep 60
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
        
    - name: Get load balancer URL and test endpoints
      run: |
        # Use the production domain name instead of raw ALB DNS to avoid SSL certificate errors
        DOMAIN="api.retainwiseanalytics.com"
        
        echo "Testing health endpoint at: https://$DOMAIN/health"
        curl -f https://$DOMAIN/health || echo "Health check failed"
        
        echo "Testing version endpoint at: https://$DOMAIN/__version"
        VERSION_RESPONSE=$(curl -s https://$DOMAIN/__version)
        echo "Version response: $VERSION_RESPONSE"
        
        # Verify version endpoint contains expected fields
        if echo "$VERSION_RESPONSE" | jq -e '.commit_sha, .build_time, .deployment_id' > /dev/null; then
          echo "‚úÖ Version endpoint working correctly!"
          echo "‚úÖ Deployment verified successfully!"
        else
          echo "‚ùå Version endpoint missing expected fields"
          exit 1
        fi 
